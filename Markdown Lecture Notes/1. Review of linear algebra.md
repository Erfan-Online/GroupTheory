# Review of Linear Algebra

**$n \times n$ Matrices**:
$$
\begin{pmatrix}
a_{11} & a_{12} & ...  & a_{1n} \\
... & ... & ... & ... \\
... & ... & a_{ij} & ...\\\ \\
a_{n1} & a_{n2} & ...  & a_{nn} \\
\end{pmatrix}
$$

For now, we only deal with Real matrices, i.e. $a_{ij} \in \mathbb{R}$

**Notation**: \
$M_n(\mathbb{R})$ is the set of all $n \times n$ matrices with entries in $\mathbb{R}$, which makes up the $\mathbb{R}$ vector space of dimension $n^2$.

Denoting the entries of $A$ with $a_{ij}$ and the entries of $B$ with $b_{ij}$,

We can **add** these matrices:
$$
(A + B)_{ij} = A_{ij} + B_{ij}
$$

We can do **scalar multiplication**:
$$
\alpha \in \mathbb{R}, \quad (\alpha A)_{ij} = \alpha \times A_{ij}
$$

We can **multiply matrices**:
$$
(A \times B)_{ij} = \sum_k a_{ik} b_{kj}
$$
In other words, $(A \times B)_{ij}$ is the dot product of the $i$-th row of $A$ with the $j$-th column of $B$.

**Note**: Matrices are linear operators.

If $A$ represents $T: \mathbb{R}^n \rightarrow \mathbb{R}^n$ and $B$ represents $S: \mathbb{R}^n \rightarrow \mathbb{R}^n$, then $AB$ represents the composition $T\circ S$

_Addition_ of matrices is **commutative**:
$$
A + B = B + A
$$

But _multiplication_ is **not commutative**: 
(might be true in some cases, but not in general)

For example,
$$
\begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}
\begin{pmatrix}
0 & 0 \\
0 & 1
\end{pmatrix} = 
\begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix}
$$
but,
$$
\begin{pmatrix}
0 & 0 \\
0 & 1
\end{pmatrix} 
\begin{pmatrix}
0 & 1 \\
0 & 0
\end{pmatrix} = 
\begin{pmatrix}
0 & 0 \\
0 & 0
\end{pmatrix} = \textbf{0}
$$

The $\begin{pmatrix} 0 & 0 \\ 0 & 0 \end{pmatrix}$ matrix is the **zero element** of the $M_n(\mathbb{R})$ as a vector space, meaning that 
$$
\textbf{0} + A = A + \textbf{0} = A
$$

The **identity** matrix is defined as:
$$
I = \begin{pmatrix}
1 & 0 & ... & 0 \\
0 & 1 & ... & 0 \\
... & ... & ... & ... \\
0 & ... & ... & 1
\end{pmatrix}
$$
The identity matrix is the **unit element** of $M_n(\mathbb{R})$, meaning that 
$$
AI = IA = A
$$

**Distributive Law**:
$$
(A + B) C = AC + BC
$$

**Associativity**:
$$
(A  B) C = A (B  C)
$$


**Note**:
To prove associativity, reinterpret matrices as linear transformations. The result then follows from associativity of compositions.

### Invertible Matrices

We say $A$ is **invertible** $\leftrightarrow$ $\exists$ a matrix $B$ such that $AB = BA = I$.

**Notes**:
1. Not all matrices are invertible. 
For example, $0$ cannot be invertible, since $\textbf{0}A = \textbf{0} = A \textbf{0}$.

2. $I$ is invertible, since $II = II^{-1} = I$.

3. A $1\times1$ matrix is invertible, $\leftrightarrow$ $a \neq 0$. 
($A^{-1} = \frac{1}{A}$)

4. $2 \times 2$ matrices $A = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$ are invertible, $\leftrightarrow det(A) = ad - bc \neq 0$. \
Then, $A^{-1} = \frac{1}{det(A)} \begin{pmatrix} d & -c \\ -b & a \end{pmatrix}$.
$\begin{pmatrix} d & -c \\ -b & a \end{pmatrix}$ is called the matrix of _cofactors_.

5. If the inverse of a matrix exists, it is **unique**.
    _Proof_: 
    $$
    \begin{align*}
    \text{Suppose} &\quad AB = AC = I, \\
    \rightarrow &\quad 
    B(AB) = B(AC) \\
    \quad &=(BA)B = (BA)C  \\
    \quad &= IB = IC \\
    \quad &= B = C
    \end{align*}
    $$

<br/>

# Groups

### General Linear group - $GL_n(\mathbb{R})$
In this course, we're more interested in the subset 
$$
\begin{align*}
GL_n(\mathbb{R}) &:= \{A \, : \, det(A) \neq 0\} \\
&= \{A \, : \exists A^{-1} \} \\
& \subset M_n(\mathbb{R})
\end{align*}
$$
Which is called the **General Linear group**.

By restricting ourselves to $GL_n(\mathbb{R})$, we gain some things but lose others.

#### Properties

- There is _no addition law_ on $GL_n(\mathbb{R})$. \
    i.e. $A + B \notin GL_n(\mathbb{R})$. \
    e.g. $A + -A = \textbf{0} \notin GL_n(\mathbb{R})$.

- It's also not closed under scalar multiplication by $0$. \
    $0 \times A = \textbf{0} \notin GL_n(\mathbb{R})$

- But it is **closed under (matrix) multiplication**. \
    Two **Proofs**:
    1. Suppose $A$ and $B$ are invertible. 
    Then, $AB$ is invertible, since:
    $$
    \begin{align*}
    (B^{-1} A^{-1})(AB) &= B^{-1}(A^{-1}A)B \\
    &= B^{-1}IB \\ 
    &= I
    \end{align*}
    $$

    2. Using determinant identity:
    $$
    det(AB) = det(A) \times det(B)
    $$
    Then, using
    $$
        GL_n(\mathbb{R}) = \{A \, : \, det(A) \neq 0\} 
    $$
    We see that $AB$ is a member of $GL_n(\mathbb{R})$.

- It has a multiplication identity, $I$.
- $\forall A \in GL_n(\mathbb{R}) \rightarrow A^{-1} \in GL_n(\mathbb{R})$
- Products in it are associative. $(AB) C = A (BC)$

The last $3$ properties are the ones that define the notion of a **group**.

<br/>

## Defining a group
A **group** $G$ is a set with a product operation $\cdot$ where for $g, h \in G$, we have $g \cdot h \in G$ such that:
1. It is _Associative_.
2. It has an identity element $I$ (also referred to as $e$).
3. Every element $g \in G$ has an inverse element $g^{-1} \in G$ such that $g^{-1}g = gg^{-1} = e$.

The common notation for denoting a group is $G = (\text{set of elements}, \text{product operation})$. \
e.g. $GL_n(\mathbb{R}) = (\text{invertible matrices}, \text{matrix multiplication})$ \
e.g. The set of integers $\mathbb{Z}$ with addition is a group denoted as $G = (\mathbb{Z}, +)$.

**Note**:
If $gh = hg$ for all pairs of elements $g, h \in G$, then $G$ is called a **commutative group**, also known as an **Abelian group**.

An example of an Abelian group is the **set of integers**:
$$
\mathbb{Z} = \{0, \pm 1, \pm 2, \pm 3, ... \}
$$

Its "product" operation is _addition_:
$$
a + b = b + a \\
e = 0, \quad a + 0 = a \\
"a^{-1}" = -a
$$

Another example of an Abelian group is **any vector space**, excluding any _scalar multiplication_.

<br/>

### Symmetry Group - $Sym(T)$
This is the most "general" example of a group. 
Suppose $T$ is a set, then 
$$
G = \{ \text{all bijections } g: T \rightarrow T \} = Sym(T)
$$
is a group under the composition of transformations. \
Remember that a _bijection_ is a **1-to-1, onto** map, which means that this is a set of all 1-to-1 and onto maps whose domain and range are both $T$.

#### Properties
- _Identity_: $e := x \mapsto x$ is the identity element.
- _Inverses_ exist by bijectivity.
- _Associativity_: $g(h(x)) = (g(h))(x)$, which follows by definition.

In some sense, this is the most general group, because groups arise as bijections of a set which preserve the structure (Symmetries) of a set.

For example
$$
T = {1, \, \dots \, , n} \text{ is a set.} \\
S_n := Sym(T) \\
$$
$S_n$ is the set of **all** bijections and a finite group of size $n!$

Interestingly, $S_3$ is **not Abelian**.